{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edac6a6e",
   "metadata": {},
   "source": [
    "# Perplexity computation"
   ]
  },
  {
   "cell_type": "code",
   "id": "de3b2eab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T22:54:55.424770Z",
     "start_time": "2025-09-11T22:54:55.422291Z"
    }
   },
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "\n",
    "from gensim.utils import simple_preprocess"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "d86360b0",
   "metadata": {},
   "source": [
    "### Defining the Training and Test Data\n",
    "\n",
    "We start by creating a **small training corpus**, which consists of a few simple sentences.  \n",
    "This corpus will serve as the \"knowledge base\" from which our model learns word probabilities.  \n",
    "\n",
    "Next, we define a **test sentence**.  \n",
    "Perplexity will be computed on this sentence to measure how well the probability distribution learned from the training corpus predicts unseen text.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5191859d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T22:54:59.308650Z",
     "start_time": "2025-09-11T22:54:59.305244Z"
    }
   },
   "source": [
    "# Sample training corpus demonstrating perplexity computation\n",
    "training_corpus = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog ran in the park\", \n",
    "    \"a cat likes fish\",\n",
    "    \"the mat is soft\"\n",
    "]\n",
    "\n",
    "# Test sentence for perplexity calculation\n",
    "test_sentence = \"the cat likes the mat\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "afed3401",
   "metadata": {},
   "source": [
    "### Building a Bigram Model\n",
    "\n",
    "This block:\n",
    "- Tokenizes sentences with `<s>` and `</s>` markers.  \n",
    "- Counts **unigrams** (single words) and **bigrams** (word pairs).  \n",
    "- Prints the counts to show what the model has learned.  \n",
    "\n",
    "We also tokenize the test sentence so itâ€™s ready for probability and perplexity calculation later.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7703ad06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T23:06:59.885219Z",
     "start_time": "2025-09-11T23:06:59.878584Z"
    }
   },
   "source": [
    "# Tokenize and add special tokens\n",
    "def tokenize_with_boundaries(sentence: str) -> List[str]:\n",
    "    # TODO: return list of tokens with <s> at the start and </s> at the end\n",
    "    return ['<s>'] + sentence.split() + ['</s>']  # Replace with actual tokenization logic\n",
    "    pass\n",
    "\n",
    "# Build bigram counts\n",
    "bigram_counts = defaultdict(int)\n",
    "unigram_counts = defaultdict(int)\n",
    "\n",
    "# Tokenizing and counting\n",
    "print(f\"Tokenized corpus\")\n",
    "for sentence in training_corpus:\n",
    "    tokens = tokenize_with_boundaries(sentence)\n",
    "    print(f\"\\tTokens: {tokens}\")\n",
    "    \n",
    "    # TODO: count unigrams\n",
    "    for token in tokens:\n",
    "        unigram_counts[token] += 1\n",
    "    \n",
    "    # TODO: count bigrams\n",
    "    for i in range(len(tokens) - 1):\n",
    "        bigram = (tokens[i], tokens[i + 1])\n",
    "        bigram_counts[bigram] += 1\n",
    "\n",
    "print(f\"\\nUnigram counts:\")\n",
    "for word, count in sorted(unigram_counts.items()):\n",
    "    print(f\"   {word}: {count}\")\n",
    "\n",
    "print(f\"\\nBigram counts:\")\n",
    "for bigram, count in sorted(bigram_counts.items()):\n",
    "    print(f\"   {bigram}: {count}\")\n",
    "\n",
    "test_tokens = tokenize_with_boundaries(test_sentence)\n",
    "print(f\"\\nTokenized test sentence: {test_tokens}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized corpus\n",
      "\tTokens: ['<s>', 'the', 'cat', 'sat', 'on', 'the', 'mat', '</s>']\n",
      "\tTokens: ['<s>', 'the', 'dog', 'ran', 'in', 'the', 'park', '</s>']\n",
      "\tTokens: ['<s>', 'a', 'cat', 'likes', 'fish', '</s>']\n",
      "\tTokens: ['<s>', 'the', 'mat', 'is', 'soft', '</s>']\n",
      "\n",
      "Unigram counts:\n",
      "   </s>: 4\n",
      "   <s>: 4\n",
      "   a: 1\n",
      "   cat: 2\n",
      "   dog: 1\n",
      "   fish: 1\n",
      "   in: 1\n",
      "   is: 1\n",
      "   likes: 1\n",
      "   mat: 2\n",
      "   on: 1\n",
      "   park: 1\n",
      "   ran: 1\n",
      "   sat: 1\n",
      "   soft: 1\n",
      "   the: 5\n",
      "\n",
      "Bigram counts:\n",
      "   ('<s>', 'a'): 1\n",
      "   ('<s>', 'the'): 3\n",
      "   ('a', 'cat'): 1\n",
      "   ('cat', 'likes'): 1\n",
      "   ('cat', 'sat'): 1\n",
      "   ('dog', 'ran'): 1\n",
      "   ('fish', '</s>'): 1\n",
      "   ('in', 'the'): 1\n",
      "   ('is', 'soft'): 1\n",
      "   ('likes', 'fish'): 1\n",
      "   ('mat', '</s>'): 1\n",
      "   ('mat', 'is'): 1\n",
      "   ('on', 'the'): 1\n",
      "   ('park', '</s>'): 1\n",
      "   ('ran', 'in'): 1\n",
      "   ('sat', 'on'): 1\n",
      "   ('soft', '</s>'): 1\n",
      "   ('the', 'cat'): 1\n",
      "   ('the', 'dog'): 1\n",
      "   ('the', 'mat'): 2\n",
      "   ('the', 'park'): 1\n",
      "\n",
      "Tokenized test sentence: ['<s>', 'the', 'cat', 'likes', 'the', 'mat', '</s>']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "fd151043",
   "metadata": {},
   "source": [
    "### Bigram Probabilities with Add-1 Smoothing\n",
    "\n",
    "Now we compute bigram probabilities.  \n",
    "To avoid zero probabilities for unseen word pairs, we use **add-1 smoothing** (Laplace smoothing).  \n",
    "\n",
    "For each bigram in the test sentence:\n",
    "- The probability is `(count(w1, w2) + 1) / (count(w1) + |V|)`.  \n",
    "- We also compute `log2(prob)` for use in perplexity calculation.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T23:07:54.514686Z",
     "start_time": "2025-09-11T23:07:54.512041Z"
    }
   },
   "cell_type": "code",
   "source": "len(bigram_counts)",
   "id": "6ccd5445a8327764",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "9fe2f068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T23:10:54.632806Z",
     "start_time": "2025-09-11T23:10:54.628381Z"
    }
   },
   "source": [
    "vocab_size = len(unigram_counts)\n",
    "\n",
    "def get_bigram_prob_smoothed(w1: str, w2: str) -> float:\n",
    "    \"\"\"Get bigram probability with add-1 smoothing\"\"\"\n",
    "    # TODO: Implement formula (hint: slide 41)\n",
    "    numerator = bigram_counts[(w1, w2)] + 1\n",
    "    denominator = unigram_counts[w1] + vocab_size\n",
    "    return numerator / denominator\n",
    "\n",
    "print(f\"Computing the Bigram probabilities:\")\n",
    "log_prob_sum = 0\n",
    "n_tokens = len(test_tokens) - 1  # Number of bigrams\n",
    "\n",
    "for i in range(len(test_tokens) - 1):\n",
    "    w1, w2 = test_tokens[i], test_tokens[i + 1]\n",
    "    # TODO: compute probability and log2(prob)\n",
    "    prob = get_bigram_prob_smoothed(w1, w2)\n",
    "    log_prob = math.log2(prob)\n",
    "    log_prob_sum += log_prob\n",
    "    \n",
    "    print(f\"   P({w2}|{w1}) = ({bigram_counts[(w1, w2)]} + 1) / ({unigram_counts[w1]} + {vocab_size}) = {prob:.4f}\")\n",
    "    print(f\"   log2({prob:.4f}) = {log_prob:.4f}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the Bigram probabilities:\n",
      "   P(the|<s>) = (3 + 1) / (4 + 16) = 0.2000\n",
      "   log2(0.2000) = -2.3219\n",
      "\n",
      "   P(cat|the) = (1 + 1) / (5 + 16) = 0.0952\n",
      "   log2(0.0952) = -3.3923\n",
      "\n",
      "   P(likes|cat) = (1 + 1) / (2 + 16) = 0.1111\n",
      "   log2(0.1111) = -3.1699\n",
      "\n",
      "   P(the|likes) = (0 + 1) / (1 + 16) = 0.0588\n",
      "   log2(0.0588) = -4.0875\n",
      "\n",
      "   P(mat|the) = (2 + 1) / (5 + 16) = 0.1429\n",
      "   log2(0.1429) = -2.8074\n",
      "\n",
      "   P(</s>|mat) = (1 + 1) / (2 + 16) = 0.1111\n",
      "   log2(0.1111) = -3.1699\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "0a5b3bc5",
   "metadata": {},
   "source": [
    "### Perplexity Computation\n",
    "\n",
    "Finally, we calculate **perplexity** of the test sentence under our bigram model:  \n",
    "\n",
    "\\begin{align}\n",
    "\\text{Perplexity} = 2^{-\\frac{1}{N} \\sum \\log_2 P(w_i \\mid w_{i-1})}\n",
    "\\end{align}\n",
    "\n",
    "- `N` = number of bigrams in the test sentence.  \n",
    "- We average the log probabilities and exponentiate to get perplexity.  \n",
    "\n",
    "A **lower perplexity** means the model finds the test sentence more predictable.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a6b7501f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T23:12:23.565081Z",
     "start_time": "2025-09-11T23:12:23.561528Z"
    }
   },
   "source": [
    "print(f\"\\nPerplexity calculation:\")\n",
    "print(f\"   Sum of log probabilities: {log_prob_sum:.4f}\")\n",
    "print(f\"   Number of tokens (N): {n_tokens}\")\n",
    "\n",
    "# TODO: Compute perplexity (hint: equation above + slide 30)\n",
    "perplexity = 2 ** (-log_prob_sum / n_tokens)\n",
    "print(f\"   Perplexity = {perplexity:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity calculation:\n",
      "   Sum of log probabilities: -18.9489\n",
      "   Number of tokens (N): 6\n",
      "   Perplexity = 8.9269\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "64d27d0f",
   "metadata": {},
   "source": [
    "## MCQ\n",
    "\n",
    "### 4.1. Definition of Perplexity  \n",
    "\n",
    "What does perplexity measure in language models?  \n",
    "\n",
    "A. The total number of words in the test set<br>  \n",
    "B. The unpredictability or \"surprise\" of a model when predicting text<br>  \n",
    "C. The size of the vocabulary<br>  \n",
    "D. The average frequency of bigrams<br>  \n",
    "\n",
    "**Answer:** \n",
    "\n",
    "---\n",
    "\n",
    "### 4.2. Formula for Perplexity  \n",
    "\n",
    "Which of the following is the correct formula for perplexity of a test set with *N* tokens?  \n",
    "\n",
    "A. $\\text{Perplexity} = \\frac{1}{N} \\sum \\log P(w_i)$<br>  \n",
    "B. $\\text{Perplexity} = 2^{-\\frac{1}{N} \\sum \\log_2 P(w_i \\mid context)}$<br>  \n",
    "C. $\\text{Perplexity} = \\prod_{i=1}^{N} P(w_i)$<br>  \n",
    "D. $\\text{Perplexity} = N^{\\sum P(w_i)}$<br>  \n",
    "\n",
    "**Answer:** \n",
    "\n",
    "---\n",
    "\n",
    "### 4.3. Interpretation of Perplexity  \n",
    "\n",
    "If a model has **lower perplexity** on a test set, what does it mean?  \n",
    "\n",
    "A. The model is more confident and better at predicting the test data<br>  \n",
    "B. The model is overfitting<br>  \n",
    "C. The vocabulary size is smaller<br>  \n",
    "D. The training corpus is too simple<br>  \n",
    "\n",
    "**Answer:** \n",
    "\n",
    "---\n",
    "\n",
    "### 4.4. Smoothing and Perplexity  \n",
    "\n",
    "Why is **add-1 smoothing (Laplace smoothing)** used when computing perplexity?  \n",
    "\n",
    "A. To reduce the vocabulary size<br>  \n",
    "B. To ensure unseen word pairs do not get zero probability<br>  \n",
    "C. To increase the average log probability<br>  \n",
    "D. To make the model faster to train<br>  \n",
    "\n",
    "**Answer:**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_private",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
